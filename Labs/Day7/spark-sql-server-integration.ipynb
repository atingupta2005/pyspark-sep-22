{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dacfa117",
   "metadata": {},
   "source": [
    "# Spark integration with SQL Server\n",
    "- Create PAAS SQL DB in Azure\n",
    "- In Firewall settings of SQL Server, enable all the IP address to connect from\n",
    "- Import Sample data in SQL Server:    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a3675",
   "metadata": {},
   "source": [
    "```\n",
    "CREATE TABLE dbo.Customer\n",
    "(CustomerID INT IDENTITY(1,1) NOT NULL,\n",
    "FirstName VARCHAR(25) NOT NULL,\n",
    "LastName VARCHAR(25) NOT NULL,\n",
    "PhoneNumber VARCHAR(15) NOT NULL,\n",
    "EmailAddress VARCHAR(25) NULL,\n",
    "Priority INT NOT NULL,\n",
    "CreateDate DATETIME NOT NULL)ON [PRIMARY]\n",
    "GO\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6d49d7",
   "metadata": {},
   "source": [
    "```\n",
    "INSERT INTO [dbo].[Customer]\n",
    " ([FirstName]\n",
    " ,[LastName]\n",
    " ,[PhoneNumber]\n",
    " ,[EmailAddress]\n",
    " ,[Priority]\n",
    " ,[CreateDate])\n",
    "VALUES\n",
    " ('Jonah'\n",
    " ,'Hook'\n",
    " ,'777-777-7777'\n",
    " ,'jonah@neverdull.com'\n",
    " ,1\n",
    " ,'2011-09-01')\n",
    "GO\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db70de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required modules\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd3e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9690c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pyspark --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da91a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!spark-submit --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2915c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!spark-shell --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd6544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!spark-sql --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9807062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = f'--packages com.microsoft.sqlserver:mssql-jdbc:11.2.1.jre8 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df3be683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.9/dist-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "com.microsoft.sqlserver#mssql-jdbc added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-157c6872-8c5f-4b53-a52f-ff5bae4037cc;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.microsoft.sqlserver#mssql-jdbc;11.2.1.jre8 in central\n",
      ":: resolution report :: resolve 401ms :: artifacts dl 2ms\n",
      "\t:: modules in use:\n",
      "\tcom.microsoft.sqlserver#mssql-jdbc;11.2.1.jre8 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-157c6872-8c5f-4b53-a52f-ff5bae4037cc\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/4ms)\n",
      "22/09/11 03:05:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/09/11 03:05:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"SQL Integration using JDBC\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfb269a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set variable to be used to connect the database\n",
    "server = \"sqlsvrspark\"\n",
    "database = \"sqldbspark\"\n",
    "table = \"production.brands\"\n",
    "user = \"atingupta2005\"\n",
    "password  = \"Azure@123456\"\n",
    "url = f\"jdbc:sqlserver://{server}.database.windows.net:1433;database={database}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd8da951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jdbc:sqlserver://sqlsvrspark.database.windows.net:1433;database=sqldbspark;user=atingupta2005@sqlsvrspark;password={your_password_here};encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a874a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"url\": url,\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"dbtable\": \"dbo.Customer\",\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09fd60bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbcDF = spark.read.format(\"jdbc\").options(**options).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96571645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------+------------+-------------------+--------+-------------------+\n",
      "|CustomerID|FirstName|LastName| PhoneNumber|       EmailAddress|Priority|         CreateDate|\n",
      "+----------+---------+--------+------------+-------------------+--------+-------------------+\n",
      "|         1|    Jonah|    Hook|777-777-7777|jonah@neverdull.com|       1|2011-09-01 00:00:00|\n",
      "+----------+---------+--------+------------+-------------------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdbcDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ca2dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "options_write = {\n",
    "    \"url\": url,\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"dbtable\": \"dbo.Customer_wtite\",\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "079aa70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jdbcDF.write.format(\"jdbc\").options(**options_write).mode(\"append\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e7bcd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------+------------+-------------------+--------+-------------------+\n",
      "|CustomerID|FirstName|LastName| PhoneNumber|       EmailAddress|Priority|         CreateDate|\n",
      "+----------+---------+--------+------------+-------------------+--------+-------------------+\n",
      "|         1|    Jonah|    Hook|777-777-7777|jonah@neverdull.com|       1|2011-09-01 00:00:00|\n",
      "|         1|    Jonah|    Hook|777-777-7777|jonah@neverdull.com|       1|2011-09-01 00:00:00|\n",
      "|         1|    Jonah|    Hook|777-777-7777|jonah@neverdull.com|       1|2011-09-01 00:00:00|\n",
      "|         1|    Jonah|    Hook|777-777-7777|jonah@neverdull.com|       1|2011-09-01 00:00:00|\n",
      "|         1|    Jonah|    Hook|777-777-7777|jonah@neverdull.com|       1|2011-09-01 00:00:00|\n",
      "+----------+---------+--------+------------+-------------------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdbcDF_written = spark.read.format(\"jdbc\").options(**options_write).load()\n",
    "jdbcDF_written.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf99c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
