{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e073adae-ebb4-457b-a020-230eda80d9cf",
   "metadata": {},
   "source": [
    "## Processing a Slowly Changing Dimension Type 2 Using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c95e44d-dcc7-4134-9338-74560a9b24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"scd2_demo\").getOrCreate()\n",
    "v_s3_path = \"/mnt/data/data/scd2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b562a60-18a1-45fa-8f94-c80bd2e1632a",
   "metadata": {},
   "source": [
    "## Create SCD2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2753a070-eff5-4356-94ee-f2adfec5d205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+---------+--------------+------------------+------------+-----+----------+---------------+--------------+------------+----------+\n",
      "|customer_dim_key|first_name|last_name|middle_initial|address           |city        |state|zip_code  |customer_number|eff_start_date|eff_end_date|is_current|\n",
      "+----------------+----------+---------+--------------+------------------+------------+-----+----------+---------------+--------------+------------+----------+\n",
      "|1               |John      |Smith    |G             |123 Main Street   |Springville |VT   |01234-5678|289374         |2014-01-01    |9999-12-31  |true      |\n",
      "|2               |Susan     |Jones    |L             |987 Central Avenue|Central City|MO   |49257-2657|862447         |2015-03-23    |2018-11-17  |false     |\n",
      "|3               |Susan     |Harris   |L             |987 Central Avenue|Central City|MO   |49257-2657|862447         |2018-11-18    |9999-12-31  |true      |\n",
      "|4               |William   |Chase    |X             |57895 Sharp Way   |Oldtown     |CA   |98554-1285|31568          |2018-12-07    |9999-12-31  |true      |\n",
      "+----------------+----------+---------+--------------+------------------+------------+-----+----------+---------------+--------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ############## generate current_scd2 dataset ############## #\n",
    "hd_current_scd2 = \"\"\"\n",
    " SELECT   BIGINT(1) AS customer_dim_key,\n",
    "          STRING('John') AS first_name,\n",
    "          STRING('Smith') AS last_name,\n",
    "          STRING('G') AS middle_initial,\n",
    "          STRING('123 Main Street') AS address,\n",
    "          STRING('Springville') AS city,\n",
    "          STRING('VT') AS state,\n",
    "          STRING('01234-5678') AS zip_code,\n",
    "          BIGINT(289374) AS customer_number,\n",
    "          DATE('2014-01-01') AS eff_start_date,\n",
    "          DATE('9999-12-31') AS eff_end_date,\n",
    "          BOOLEAN(1) AS is_current\n",
    " UNION\n",
    " SELECT   BIGINT(2) AS customer_dim_key,\n",
    "          STRING('Susan') AS first_name,\n",
    "          STRING('Jones') AS last_name,\n",
    "          STRING('L') AS middle_initial,\n",
    "          STRING('987 Central Avenue') AS address,\n",
    "          STRING('Central City') AS city,\n",
    "          STRING('MO') AS state,\n",
    "          STRING('49257-2657') AS zip_code,\n",
    "          BIGINT(862447) AS customer_number,\n",
    "          DATE('2015-03-23') AS eff_start_date,\n",
    "          DATE('2018-11-17') AS eff_end_date,\n",
    "          BOOLEAN(0) AS is_current\n",
    " UNION\n",
    " SELECT   BIGINT(3) AS customer_dim_key,\n",
    "          STRING('Susan') AS first_name,\n",
    "          STRING('Harris') AS last_name,\n",
    "          STRING('L') AS middle_initial,\n",
    "          STRING('987 Central Avenue') AS address,\n",
    "          STRING('Central City') AS city,\n",
    "          STRING('MO') AS state,\n",
    "          STRING('49257-2657') AS zip_code,\n",
    "          BIGINT(862447) AS customer_number,\n",
    "          DATE('2018-11-18') AS eff_start_date,\n",
    "          DATE('9999-12-31') AS eff_end_date,\n",
    "          BOOLEAN(1) AS is_current\n",
    " UNION\n",
    " SELECT   BIGINT(4) AS customer_dim_key,\n",
    "          STRING('William') AS first_name,\n",
    "          STRING('Chase') AS last_name,\n",
    "          STRING('X') AS middle_initial,\n",
    "          STRING('57895 Sharp Way') AS address,\n",
    "          STRING('Oldtown') AS city,\n",
    "          STRING('CA') AS state,\n",
    "          STRING('98554-1285') AS zip_code,\n",
    "          BIGINT(31568) AS customer_number,\n",
    "          DATE('2018-12-07') AS eff_start_date,\n",
    "          DATE('9999-12-31') AS eff_end_date,\n",
    "          BOOLEAN(1) AS is_current\n",
    "\"\"\"\n",
    "df_current_scd2 = spark.sql(hd_current_scd2)\n",
    "df_current_scd2.coalesce(1).write.mode(\"overwrite\").parquet(v_s3_path + \"/current_scd2/\")\n",
    "df_current_scd2.createOrReplaceTempView(\"current_scd2\")\n",
    "# ############## review dataset ############## #\n",
    "df_current_scd2 = spark.read.parquet(v_s3_path + \"/current_scd2/*\").orderBy(\"customer_dim_key\")\n",
    "df_current_scd2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ed226-40e2-4c8e-95f8-76babb2713de",
   "metadata": {},
   "source": [
    "## Create customer dataset from source system "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60180f-a27e-41e1-837f-bbe1b60586c6",
   "metadata": {},
   "source": [
    "- Use the following script to generate your source data, which I will use to modify our SCD2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc0d635-4adf-43a6-a0b0-c4c278e4d762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+--------------+------------------+------------+-----+----------+\n",
      "|customer_number|first_name|last_name|middle_initial|address           |city        |state|zip_code  |\n",
      "+---------------+----------+---------+--------------+------------------+------------+-----+----------+\n",
      "|31568          |William   |Chase    |X             |57895 Sharp Way   |Oldtown     |CA   |98554-1285|\n",
      "|289374         |John      |Smith    |G             |456 Derry Court   |Springville |VT   |01234-5678|\n",
      "|862447         |Susan     |Harris   |L             |987 Central Avenue|Central City|MO   |49257-2657|\n",
      "|932574         |Lisa      |Cohen    |S             |69846 Mason Road  |Atlanta     |GA   |26584-3591|\n",
      "+---------------+----------+---------+--------------+------------------+------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ############## generate customer_data dataset ############## #\n",
    "hd_customer_data = \"\"\"\n",
    " SELECT   BIGINT(289374) AS customer_number,\n",
    "          STRING('John') AS first_name,\n",
    "          STRING('Smith') AS last_name,\n",
    "          STRING('G') AS middle_initial,\n",
    "          STRING('456 Derry Court') AS address,\n",
    "          STRING('Springville') AS city,\n",
    "          STRING('VT') AS state,\n",
    "          STRING('01234-5678') AS zip_code\n",
    " UNION\n",
    " SELECT   BIGINT(932574) AS customer_number,\n",
    "          STRING('Lisa') AS first_name,\n",
    "          STRING('Cohen') AS last_name,\n",
    "          STRING('S') AS middle_initial,\n",
    "          STRING('69846 Mason Road') AS address,\n",
    "          STRING('Atlanta') AS city,\n",
    "          STRING('GA') AS state,\n",
    "          STRING('26584-3591') AS zip_code\n",
    " UNION\n",
    " SELECT   BIGINT(862447) AS customer_number,\n",
    "          STRING('Susan') AS first_name,\n",
    "          STRING('Harris') AS last_name,\n",
    "          STRING('L') AS middle_initial,\n",
    "          STRING('987 Central Avenue') AS address,\n",
    "          STRING('Central City') AS city,\n",
    "          STRING('MO') AS state,\n",
    "          STRING('49257-2657') AS zip_code\n",
    " UNION\n",
    " SELECT   BIGINT(31568) AS customer_number,\n",
    "          STRING('William') AS first_name,\n",
    "          STRING('Chase') AS last_name,\n",
    "          STRING('X') AS middle_initial,\n",
    "          STRING('57895 Sharp Way') AS address,\n",
    "          STRING('Oldtown') AS city,\n",
    "          STRING('CA') AS state,\n",
    "          STRING('98554-1285') AS zip_code\n",
    "\"\"\"\n",
    "df_customer_data= spark.sql(hd_customer_data)\n",
    "df_customer_data.coalesce(1).write.mode(\"overwrite\").parquet(v_s3_path + \"/customer_data/\")\n",
    "df_customer_data.createOrReplaceTempView(\"customer_data\")\n",
    "# ############## review dataset ############## #\n",
    "df_customer_data= spark.read.parquet(v_s3_path + \"/customer_data/*\").orderBy(\"customer_number\")\n",
    "df_customer_data.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5eba296-1682-439d-bd25-e66e2cdf1c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+---------+--------------+------------------+------------+-----+----------+---------------+--------------+------------+----------+\n",
      "|customer_dim_key|first_name|last_name|middle_initial|address           |city        |state|zip_code  |customer_number|eff_start_date|eff_end_date|is_current|\n",
      "+----------------+----------+---------+--------------+------------------+------------+-----+----------+---------------+--------------+------------+----------+\n",
      "|1               |John      |Smith    |G             |123 Main Street   |Springville |VT   |01234-5678|289374         |2014-01-01    |9999-12-31  |true      |\n",
      "|2               |Susan     |Jones    |L             |987 Central Avenue|Central City|MO   |49257-2657|862447         |2015-03-23    |2018-11-17  |false     |\n",
      "|3               |Susan     |Harris   |L             |987 Central Avenue|Central City|MO   |49257-2657|862447         |2018-11-18    |9999-12-31  |true      |\n",
      "|4               |William   |Chase    |X             |57895 Sharp Way   |Oldtown     |CA   |98554-1285|31568          |2018-12-07    |9999-12-31  |true      |\n",
      "+----------------+----------+---------+--------------+------------------+------------+-----+----------+---------------+--------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_current_scd2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59639f60-5a09-41f9-97a3-9610b4fda82b",
   "metadata": {},
   "source": [
    "## Manually find changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4306d12e-de1a-482c-93b8-19cf8b820eb9",
   "metadata": {},
   "source": [
    "- Remember that the data from the source system feeds in to our SCD2, so I need to compare the two datasets to determine if there are any differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9569063-559a-447f-827b-a0a1b9854990",
   "metadata": {},
   "source": [
    "## Create new current records for existing customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b557f9-fb84-4513-820f-2cd2b344be1e",
   "metadata": {},
   "source": [
    "- In order to logically capture this address change\n",
    "- I need to compare the current SCD2 and the source data (as I did manually above) and flag changes\n",
    "- I also need to be mindful of our row metadata fields to ensure that I am expiring and starting records using the appropriate dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e30cf34-f175-4d51-a746-dd408a008b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+----------+---------+--------------+---------------+-----------+-----+----------+--------------+------------+----------+\n",
      "|customer_dim_key|customer_number|first_name|last_name|middle_initial|address        |city       |state|zip_code  |eff_start_date|eff_end_date|is_current|\n",
      "+----------------+---------------+----------+---------+--------------+---------------+-----------+-----+----------+--------------+------------+----------+\n",
      "|1               |289374         |John      |Smith    |G             |456 Derry Court|Springville|VT   |01234-5678|2022-05-21    |9999-12-31  |true      |\n",
      "+----------------+---------------+----------+---------+--------------+---------------+-----------+-----+----------+--------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ############## create new current recs dataaset ############## #\n",
    "hd_new_curr_recs = \"\"\"\n",
    " SELECT   t.customer_dim_key,\n",
    "          s.customer_number,\n",
    "          s.first_name,\n",
    "          s.last_name,\n",
    "          s.middle_initial,\n",
    "          s.address,\n",
    "          s.city,\n",
    "          s.state,\n",
    "          s.zip_code,\n",
    "          DATE(FROM_UTC_TIMESTAMP(CURRENT_TIMESTAMP, 'IST'))\n",
    "              AS eff_start_date,\n",
    "          DATE('9999-12-31') AS eff_end_date,\n",
    "          BOOLEAN(1) AS is_current\n",
    " FROM     customer_data s\n",
    "          INNER JOIN current_scd2 t\n",
    "              ON t.customer_number = s.customer_number\n",
    "              AND t.is_current = True\n",
    " WHERE    NVL(s.first_name, '') <> NVL(t.first_name, '')\n",
    "          OR NVL(s.last_name, '') <> NVL(t.last_name, '')\n",
    "          OR NVL(s.middle_initial, '') <> NVL(t.middle_initial, '')\n",
    "          OR NVL(s.address, '') <> NVL(t.address, '')\n",
    "          OR NVL(s.city, '') <> NVL(t.city, '')\n",
    "          OR NVL(s.state, '') <> NVL(t.state, '')\n",
    "          OR NVL(s.zip_code, '') <> NVL(t.zip_code, '')\n",
    "\"\"\"\n",
    "df_new_curr_recs = spark.sql(hd_new_curr_recs)\n",
    "df_new_curr_recs.coalesce(1).write.mode(\"overwrite\").parquet(v_s3_path + \"/new_curr_recs/\")\n",
    "df_new_curr_recs.createOrReplaceTempView(\"new_curr_recs\")\n",
    "# ############## review dataset ############## #\n",
    "df_new_curr_recs = spark.read.parquet(v_s3_path + \"/new_curr_recs/*\").orderBy(\"customer_number\")\n",
    "df_new_curr_recs.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83864621-e56c-4de6-828e-514518b662dc",
   "metadata": {},
   "source": [
    "- The above logic runs through all the records and finds the one change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55da201-2308-4539-8cff-291e6c30fdbf",
   "metadata": {},
   "source": [
    "## Find previous current records to expire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7763bc-dfc6-4e66-9b14-b7ff946a6cf2",
   "metadata": {},
   "source": [
    "- Now that I have the a new current record for a customer that already exists, I need to expire the previous current record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "870e89e2-0678-4c0f-a2ce-8565b6a8220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########### isolate keys of records to be modified ########### #\n",
    "df_modfied_keys = df_new_curr_recs.select(\"customer_dim_key\")\n",
    "df_modfied_keys.coalesce(1).write.mode(\"overwrite\").parquet(v_s3_path + \"/modfied_keys/\")\n",
    "df_modfied_keys.createOrReplaceTempView(\"modfied_keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95015c33-6609-4455-9e45-0ba6db823a8e",
   "metadata": {},
   "source": [
    "## Expire previous current records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242f169f-9d74-4dd0-aa68-f2c290602cb6",
   "metadata": {},
   "source": [
    "- Now I can go about expiring that prior record, while again being mindful of our row metadata fields and modifying them correctly\n",
    "- Recall that I cannot update the record, so I have to create a new instance of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6460135-e655-41cf-ba57-0f9d48135e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+----------+---------+--------------+---------------+-----------+-----+----------+--------------+------------+----------+\n",
      "|customer_dim_key|customer_number|first_name|last_name|middle_initial|address        |city       |state|zip_code  |eff_start_date|eff_end_date|is_current|\n",
      "+----------------+---------------+----------+---------+--------------+---------------+-----------+-----+----------+--------------+------------+----------+\n",
      "|1               |289374         |John      |Smith    |G             |123 Main Street|Springville|VT   |01234-5678|2014-01-01    |2022-05-20  |false     |\n",
      "+----------------+---------------+----------+---------+--------------+---------------+-----------+-----+----------+--------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ############## create new hist recs dataaset ############## #\n",
    "hd_new_hist_recs = \"\"\"\n",
    " SELECT   t.customer_dim_key,\n",
    "          t.customer_number,\n",
    "          t.first_name,\n",
    "          t.last_name,\n",
    "          t.middle_initial,\n",
    "          t.address,\n",
    "          t.city,\n",
    "          t.state,\n",
    "          t.zip_code,\n",
    "          t.eff_start_date,\n",
    "          DATE_SUB(\n",
    "              DATE(FROM_UTC_TIMESTAMP(CURRENT_TIMESTAMP, 'IST')), 1\n",
    "          ) AS eff_end_date,\n",
    "          BOOLEAN(0) AS is_current\n",
    " FROM     current_scd2 t\n",
    "          INNER JOIN modfied_keys k\n",
    "              ON k.customer_dim_key = t.customer_dim_key\n",
    " WHERE    t.is_current = True\n",
    "\"\"\"\n",
    "df_new_hist_recs = spark.sql(hd_new_hist_recs)\n",
    "df_new_hist_recs.coalesce(1).write.mode(\"overwrite\").parquet(v_s3_path + \"/new_hist_recs/\")\n",
    "df_new_hist_recs.createOrReplaceTempView(\"new_hist_recs\")\n",
    "# ############## review dataset ############## #\n",
    "df_new_hist_recs = spark.read.parquet(v_s3_path + \"/new_hist_recs/*\").orderBy(\"customer_number\")\n",
    "df_new_hist_recs.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9efa99-bdb4-4a94-a183-4b593fe32b24",
   "metadata": {},
   "source": [
    "- The above logic expires the record properly and writes to its own dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf98a1-8ec1-4e55-8cb8-10202b855523",
   "metadata": {},
   "source": [
    "## Isolate unaffected records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0992a15-cc21-4e8a-b325-239f1cc577a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+----------+---------+--------------+------------------+------------+-----+----------+--------------+------------+----------+\n",
      "|customer_dim_key|customer_number|first_name|last_name|middle_initial|address           |city        |state|zip_code  |eff_start_date|eff_end_date|is_current|\n",
      "+----------------+---------------+----------+---------+--------------+------------------+------------+-----+----------+--------------+------------+----------+\n",
      "|4               |31568          |William   |Chase    |X             |57895 Sharp Way   |Oldtown     |CA   |98554-1285|2018-12-07    |9999-12-31  |true      |\n",
      "|2               |862447         |Susan     |Jones    |L             |987 Central Avenue|Central City|MO   |49257-2657|2015-03-23    |2018-11-17  |false     |\n",
      "|3               |862447         |Susan     |Harris   |L             |987 Central Avenue|Central City|MO   |49257-2657|2018-11-18    |9999-12-31  |true      |\n",
      "+----------------+---------------+----------+---------+--------------+------------------+------------+-----+----------+--------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ############## create unaffected recs dataset ############## #\n",
    "hd_unaffected_recs = \"\"\"\n",
    " SELECT   s.customer_dim_key,\n",
    "          s.customer_number,\n",
    "          s.first_name,\n",
    "          s.last_name,\n",
    "          s.middle_initial,\n",
    "          s.address,\n",
    "          s.city,\n",
    "          s.state,\n",
    "          s.zip_code,\n",
    "          s.eff_start_date,\n",
    "          s.eff_end_date,\n",
    "          s.is_current\n",
    " FROM     current_scd2 s\n",
    "          LEFT OUTER JOIN modfied_keys k\n",
    "              ON k.customer_dim_key = s.customer_dim_key\n",
    " WHERE    k.customer_dim_key IS NULL\n",
    "\"\"\"\n",
    "df_unaffected_recs = spark.sql(hd_unaffected_recs)\n",
    "df_unaffected_recs.coalesce(1).write.mode(\"overwrite\").parquet(v_s3_path + \"/unaffected_recs/\")\n",
    "df_unaffected_recs.createOrReplaceTempView(\"unaffected_recs\")\n",
    "# ############## review dataset ############## #\n",
    "df_unaffected_recs = spark.read.parquet(v_s3_path + \"/unaffected_recs/*\").orderBy(\"customer_number\")\n",
    "df_unaffected_recs.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cbf935-2db9-432e-84de-ab3d16f88d75",
   "metadata": {},
   "source": [
    "## Create records for new customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790a7e88-224f-491a-904b-9dc545ef1641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------+--------------+----------------+-------+-----+----------+--------------+------------+----------+\n",
      "|customer_number|first_name|last_name|middle_initial|address         |city   |state|zip_code  |eff_start_date|eff_end_date|is_current|\n",
      "+---------------+----------+---------+--------------+----------------+-------+-----+----------+--------------+------------+----------+\n",
      "|932574         |Lisa      |Cohen    |S             |69846 Mason Road|Atlanta|GA   |26584-3591|2022-05-21    |9999-12-31  |true      |\n",
      "+---------------+----------+---------+--------------+----------------+-------+-----+----------+--------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ############## create new recs dataset ############## #\n",
    "hd_new_cust = \"\"\"\n",
    " SELECT   s.customer_number,\n",
    "          s.first_name,\n",
    "          s.last_name,\n",
    "          s.middle_initial,\n",
    "          s.address,\n",
    "          s.city,\n",
    "          s.state,\n",
    "          s.zip_code,\n",
    "          DATE(FROM_UTC_TIMESTAMP(CURRENT_TIMESTAMP, 'IST')) \n",
    "              AS eff_start_date,\n",
    "          DATE('9999-12-31') AS eff_end_date,\n",
    "          BOOLEAN(1) AS is_current\n",
    " FROM     customer_data s\n",
    "          LEFT OUTER JOIN current_scd2 t\n",
    "              ON t.customer_number = s.customer_number\n",
    " WHERE    t.customer_number IS NULL\n",
    "\"\"\"\n",
    "df_new_cust = spark.sql(hd_new_cust)\n",
    "df_new_cust.coalesce(1).write.mode(\"overwrite\").parquet(v_s3_path + \"/new_cust/\")\n",
    "df_new_cust.createOrReplaceTempView(\"new_cust\")\n",
    "# ############## review dataset ############## #\n",
    "df_new_cust = spark.read.parquet(v_s3_path + \"/new_cust/*\").orderBy(\"customer_number\")\n",
    "df_new_cust.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28283961-7e56-49ea-bcd8-5d22a17e310d",
   "metadata": {},
   "source": [
    "## Combine the datasets for new SCD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a94be03-b403-4181-83ba-16ec7b1211db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+---------+--------------+------------------+------------+-----+----------+---------------+--------------+------------+----------+\n",
      "|customer_dim_key|first_name|last_name|middle_initial|address           |city        |state|zip_code  |customer_number|eff_start_date|eff_end_date|is_current|\n",
      "+----------------+----------+---------+--------------+------------------+------------+-----+----------+---------------+--------------+------------+----------+\n",
      "|1               |John      |Smith    |G             |123 Main Street   |Springville |VT   |01234-5678|289374         |2014-01-01    |2022-05-20  |false     |\n",
      "|2               |Susan     |Jones    |L             |987 Central Avenue|Central City|MO   |49257-2657|862447         |2015-03-23    |2018-11-17  |false     |\n",
      "|3               |Susan     |Harris   |L             |987 Central Avenue|Central City|MO   |49257-2657|862447         |2018-11-18    |9999-12-31  |true      |\n",
      "|4               |William   |Chase    |X             |57895 Sharp Way   |Oldtown     |CA   |98554-1285|31568          |2018-12-07    |9999-12-31  |true      |\n",
      "|5               |Lisa      |Cohen    |S             |69846 Mason Road  |Atlanta     |GA   |26584-3591|932574         |2022-05-21    |9999-12-31  |true      |\n",
      "|6               |John      |Smith    |G             |456 Derry Court   |Springville |VT   |01234-5678|289374         |2022-05-21    |9999-12-31  |true      |\n",
      "+----------------+----------+---------+--------------+------------------+------------+-----+----------+---------------+--------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ############## create new scd2 dataset ############## #\n",
    "v_max_key = spark.sql(\n",
    "    \"SELECT STRING(MAX(customer_dim_key)) FROM current_scd2\"\n",
    ").collect()[0][0]\n",
    "hd_new_scd2 = \"\"\"\n",
    " WITH a_cte\n",
    " AS   (\n",
    "        SELECT     x.first_name, x.last_name,\n",
    "                   x.middle_initial, x.address,\n",
    "                   x.city, x.state, x.zip_code,\n",
    "                   x.customer_number, x.eff_start_date,\n",
    "                   x.eff_end_date, x.is_current\n",
    "        FROM       new_cust x\n",
    "        UNION ALL\n",
    "        SELECT     y.first_name, y.last_name,\n",
    "                   y.middle_initial, y.address,\n",
    "                   y.city, y.state, y.zip_code,\n",
    "                   y.customer_number, y.eff_start_date,\n",
    "                   y.eff_end_date, y.is_current\n",
    "        FROM       new_curr_recs y\n",
    "      )\n",
    "  ,   b_cte\n",
    "  AS  (\n",
    "        SELECT  ROW_NUMBER() OVER(ORDER BY a.eff_start_date)\n",
    "                    + BIGINT('{v_max_key}') AS customer_dim_key,\n",
    "                a.first_name, a.last_name,\n",
    "                a.middle_initial, a.address,\n",
    "                a.city, a.state, a.zip_code,\n",
    "                a.customer_number, a.eff_start_date,\n",
    "                a.eff_end_date, a.is_current\n",
    "        FROM    a_cte a\n",
    "      )\n",
    "  SELECT  customer_dim_key, first_name, last_name,\n",
    "          middle_initial, address,\n",
    "          city, state, zip_code,\n",
    "          customer_number, eff_start_date,\n",
    "          eff_end_date, is_current\n",
    "  FROM    b_cte\n",
    "  UNION ALL\n",
    "  SELECT  customer_dim_key, first_name,  last_name,\n",
    "          middle_initial, address,\n",
    "          city, state, zip_code,\n",
    "          customer_number, eff_start_date,\n",
    "          eff_end_date, is_current\n",
    "  FROM    unaffected_recs\n",
    "  UNION ALL\n",
    "  SELECT  customer_dim_key, first_name,  last_name,\n",
    "          middle_initial, address,\n",
    "          city, state, zip_code,\n",
    "          customer_number, eff_start_date,\n",
    "          eff_end_date, is_current\n",
    "  FROM    new_hist_recs\n",
    "\"\"\"\n",
    "df_new_scd2 = spark.sql(hd_new_scd2.replace(\"{v_max_key}\", v_max_key))\n",
    "# ############## review dataset ############## #\n",
    "df_new_scd2.coalesce(1).write.mode(\"overwrite\").parquet(v_s3_path + \"/new_scd2/\")\n",
    "df_new_scd2 = spark.read.parquet(v_s3_path + \"/new_scd2/*\").orderBy(\"customer_dim_key\")\n",
    "df_new_scd2.show(10, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
